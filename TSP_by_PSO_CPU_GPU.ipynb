{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "observation_board = pd.DataFrame(columns=[\n",
    "    \"Dataset_Size\",\n",
    "    \"Num_Particles\",        \n",
    "    \"Num_Iterations\",      \n",
    "    \"Num_Cities\",           \n",
    "    \"Device\",               \n",
    "    \"Best_Score\",          \n",
    "    \"Time_Taken(s)\",        \n",
    "    \"Global_Best_Position\"  \n",
    "])\n",
    "def log_observation(dataset_size, num_particles, num_iterations, num_cities, device, best_score, time_taken, global_best_position):\n",
    "    global observation_board\n",
    "    observation_board = pd.concat([\n",
    "        observation_board,\n",
    "        pd.DataFrame([{\n",
    "            \"Dataset_Size\": dataset_size,\n",
    "            \"Num_Particles\": num_particles,\n",
    "            \"Num_Iterations\": num_iterations,\n",
    "            \"Num_Cities\": num_cities,\n",
    "            \"Device\": device,\n",
    "            \"Best_Score\": best_score,\n",
    "            \"Time_Taken(s)\": time_taken,\n",
    "            \"Global_Best_Position\": global_best_position.cpu().numpy().tolist()\n",
    "        }])\n",
    "    ], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With CPU Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time as time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = \"large\"\n",
    "large_data_path = f\"/home/nirjhar/Python Codes/Machine Learning/data/archive/{dataset_size}.csv\"\n",
    "large_data = pd.read_csv(large_data_path)\n",
    "print(large_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.array(large_data['X']), np.array(large_data['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(X, Y, c=Y, cmap=plt.cm.viridis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample coordinates of cities (replace with your own)\n",
    "cities = [(X[i], Y[i]) for i in range(len(X))]\n",
    "# Function to calculate the Euclidean distance\n",
    "def euclidean_distance(coord1, coord2):\n",
    "    return np.sqrt((coord1[0] - coord2[0])**2 + (coord1[1] - coord2[1])**2)\n",
    "\n",
    "# Create the distance matrix\n",
    "def create_distance_matrix(coords):\n",
    "    n = len(coords)\n",
    "    distance_matrix = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            distance_matrix[i][j] = euclidean_distance(coords[i], coords[j])\n",
    "    return distance_matrix\n",
    "\n",
    "# Generate the distance matrix\n",
    "distance_matrix = create_distance_matrix(cities)\n",
    "\n",
    "# Display the result\n",
    "print(\"Distance Matrix:\")\n",
    "print(distance_matrix)\n",
    "print(distance_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = 'cpu'\n",
    "distance_matrix = np.array(distance_matrix)\n",
    "\n",
    "# Coordinates for cities (for visualization purposes)\n",
    "city_coordinates = cities\n",
    "\n",
    "# Function to calculate total distance of a tour\n",
    "def calculate_total_distance(tour, distance_matrix):\n",
    "    total_distance = 0\n",
    "    for i in range(len(tour) - 1):\n",
    "        total_distance += distance_matrix[tour[i], tour[i + 1]]\n",
    "    total_distance += distance_matrix[tour[-1], tour[0]]  # Return to start\n",
    "    return total_distance\n",
    "\n",
    "# PSO parameters\n",
    "num_particles = 10\n",
    "num_iterations = 40000\n",
    "num_cities = distance_matrix.shape[0]\n",
    "\n",
    "# Initialize particles to be done by Model in future\n",
    "particles = [random.sample(range(num_cities), num_cities) for _ in range(num_particles)] # Initialising all the PARTICLES(A Route) in particles=[particle1, particle2, particle3, .... , particleN]\n",
    "personal_best_positions = particles.copy()\n",
    "personal_best_scores = [calculate_total_distance(p, distance_matrix) for p in particles] # score is same as distance covered while travelling through the cities\n",
    "global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n",
    "global_best_score = min(personal_best_scores)\n",
    "\n",
    "best_scores = []\n",
    "\n",
    "# PSO main loop\n",
    "start = time.time()\n",
    "\n",
    "for iteration in tqdm(range(num_iterations)):\n",
    "    for i in range(num_particles):\n",
    "        # Velocities defined by swaping random cities in a route for exploration of all routes approximately\n",
    "        new_position = particles[i][:]\n",
    "        city1, city2 = random.sample(range(num_cities), 2)\n",
    "        new_position[city1], new_position[city2] = new_position[city2], new_position[city1]\n",
    "\n",
    "        new_score = calculate_total_distance(new_position, distance_matrix)\n",
    "\n",
    "        if new_score < personal_best_scores[i]:\n",
    "            personal_best_positions[i] = new_position\n",
    "            personal_best_scores[i] = new_score\n",
    "\n",
    "        if new_score < global_best_score:\n",
    "            global_best_position = new_position\n",
    "            global_best_score = new_score\n",
    "\n",
    "    particles = personal_best_positions.copy()\n",
    "    \n",
    "    # Accumulate the global best score for plotting\n",
    "    best_scores.append(global_best_score)\n",
    "    \n",
    "end = time.time()\n",
    "\n",
    "log_observation(\n",
    "        dataset_size=dataset_size,\n",
    "        num_particles=num_particles,\n",
    "        num_iterations=num_iterations,\n",
    "        num_cities=num_cities,\n",
    "        device=device,\n",
    "        best_score=global_best_score.item(),\n",
    "        time_taken=(end - start),\n",
    "        global_best_position=torch.tensor(global_best_position)\n",
    "    )\n",
    "\n",
    "print(f\"Best Route : {global_best_position}\")\n",
    "print(f\"Best Score = {global_best_score} units\")\n",
    "\n",
    "print(f\"Total Time Taken For Optimisation Using {num_particles} Particles , on {num_cities} Cities , for {num_iterations} Iterations = {(end-start)*1000}ms\")\n",
    "\n",
    "# Plot convergence\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.style.use(\"dark_background\")\n",
    "plt.plot(best_scores, label=\"Global Best Distance\", color=\"blue\")\n",
    "plt.title(\"Convergence of PSO for TSP\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the optimal tour\n",
    "def plot_tour(tour, coordinates):\n",
    "    if num_cities == 1000:\n",
    "        plt.figure(figsize=(100, 100))\n",
    "    if num_cities == 100:\n",
    "        plt.figure(figsize=(40, 40))\n",
    "    if num_cities == 30:\n",
    "        plt.figure(figsize=(20, 20))\n",
    "    if num_cities == 10:\n",
    "        plt.figure(figsize=(10, 10))\n",
    "    tour_coords = [coordinates[city] for city in tour + [tour[0]]]  # Close the loop\n",
    "    x, y = zip(*tour_coords)\n",
    "    plt.style.use(\"dark_background\")\n",
    "    plt.plot(x, y, marker='o', color='red', label=\"Optimal Tour\")\n",
    "    for i, coord in enumerate(coordinates):\n",
    "        plt.text(coord[0], coord[1], f\"City {i}\", fontsize=12, ha='center', va='center')\n",
    "    plt.title(\"Optimal Tour\")\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "plot_tour(global_best_position, city_coordinates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With PyTorch GPU Utlisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "NUM_PARTICLES = 10\n",
    "NUM_ITERATIONS = 100000\n",
    "DATASET_SIZE = \"large\" # large, medium, small, tiny\n",
    "\n",
    "def euclidean_distance(coords):\n",
    "    coords = torch.tensor(coords, device=device)\n",
    "    x_diff = coords[:, 0].unsqueeze(1) - coords[:, 0]\n",
    "    y_diff = coords[:, 1].unsqueeze(1) - coords[:, 1]\n",
    "    distance_matrix = torch.sqrt(x_diff**2 + y_diff**2)\n",
    "    return distance_matrix\n",
    "\n",
    "\n",
    "def calculate_total_distance_batched(tours, distance_matrix):\n",
    "    # Computes total distances for all tours in a batch.\n",
    "    distances = distance_matrix[tours[:, :-1], tours[:, 1:]].sum(dim=1)\n",
    "    distances += distance_matrix[tours[:, -1], tours[:, 0]]  # Return to start\n",
    "    return distances\n",
    "\n",
    "\n",
    "def update_particles_batched(particles, distance_matrix):\n",
    "    # Updates particles by performing random swaps and evaluating distances.\n",
    "    new_particles = particles.clone()\n",
    "    batch_size, num_cities = particles.shape\n",
    "\n",
    "    # Randomly sample cities to swap\n",
    "    indices1 = torch.randint(0, num_cities, (batch_size,), device=device)\n",
    "    indices2 = torch.randint(0, num_cities, (batch_size,), device=device)\n",
    "\n",
    "    # Swap cities\n",
    "    new_particles[range(batch_size), indices1], new_particles[range(batch_size), indices2] = (\n",
    "        new_particles[range(batch_size), indices2],\n",
    "        new_particles[range(batch_size), indices1],\n",
    "    )\n",
    "\n",
    "    # Calculate distances\n",
    "    new_scores = calculate_total_distance_batched(new_particles, distance_matrix)\n",
    "\n",
    "    return new_particles, new_scores\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load data\n",
    "dataset_size = DATASET_SIZE\n",
    "large_data_path = f\"/home/nirjhar/Python Codes/Machine Learning/data/archive/{dataset_size}.csv\"\n",
    "large_data = pd.read_csv(large_data_path)\n",
    "X, Y = torch.tensor(large_data['X'].values, device='cuda'), torch.tensor(large_data['Y'].values, device='cuda')\n",
    "\n",
    "# Create distance matrix\n",
    "cities = [(X[i], Y[i]) for i in range(len(X))]\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "distance_matrix = euclidean_distance(cities)\n",
    "\n",
    "# PSO parameters\n",
    "num_particles = NUM_PARTICLES\n",
    "num_iterations = NUM_ITERATIONS\n",
    "num_cities = distance_matrix.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize particles\n",
    "particles = torch.stack([torch.randperm(num_cities, device=device) for _ in range(num_particles)])\n",
    "personal_best_positions = particles.clone()\n",
    "personal_best_scores = calculate_total_distance_batched(particles, distance_matrix)\n",
    "global_best_position = personal_best_positions[torch.argmin(personal_best_scores)]\n",
    "global_best_score = personal_best_scores.min()\n",
    "best_scores = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# PSO main loop\n",
    "start = time.time()\n",
    "\n",
    "for iteration in tqdm(range(num_iterations)):\n",
    "    new_particles, new_scores = update_particles_batched(particles, distance_matrix)\n",
    "\n",
    "    # Update personal bests\n",
    "    better_mask = new_scores < personal_best_scores\n",
    "    personal_best_positions[better_mask] = new_particles[better_mask]\n",
    "    personal_best_scores[better_mask] = new_scores[better_mask]\n",
    "\n",
    "    # Update global best\n",
    "    min_idx = torch.argmin(personal_best_scores)\n",
    "    if personal_best_scores[min_idx] < global_best_score:\n",
    "        global_best_score = personal_best_scores[min_idx]\n",
    "        global_best_position = personal_best_positions[min_idx]\n",
    "\n",
    "    particles = personal_best_positions.clone()\n",
    "    best_scores.append(global_best_score.item())\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "log_observation(\n",
    "        dataset_size=dataset_size,\n",
    "        num_particles=num_particles,\n",
    "        num_iterations=num_iterations,\n",
    "        num_cities=num_cities,\n",
    "        device=device,\n",
    "        best_score=global_best_score.item(),\n",
    "        time_taken=(end - start),\n",
    "        global_best_position=global_best_position\n",
    "    )\n",
    "\n",
    "\n",
    "# print(f\"Best Route : {global_best_position}\")\n",
    "print(f\"Best Score = {global_best_score.item()} units\")\n",
    "print(f\"Total Time Taken For Optimization Using {num_particles} Particles, on {num_cities} Cities, for {num_iterations} Iterations = {(end - start):.2f} seconds\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plot convergence\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(best_scores, label=\"Global Best Distance\", color=\"blue\")\n",
    "plt.style.use(\"dark_background\")\n",
    "plt.title(\"Convergence of PSO for TSP\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the optimal tour\n",
    "def plot_tour(tour, coordinates):\n",
    "    if num_cities == 1000:\n",
    "        plt.figure(figsize=(100, 100))\n",
    "    if num_cities == 100:\n",
    "        plt.figure(figsize=(40, 40))\n",
    "    if num_cities == 30:\n",
    "        plt.figure(figsize=(20, 20))\n",
    "    if num_cities == 10:\n",
    "        plt.figure(figsize=(10, 10))\n",
    "    tour_coords = [coordinates[city] for city in tour] + [coordinates[tour[0]]]  # Close the loop\n",
    "    x, y = zip(*tour_coords)\n",
    "    plt.style.use(\"dark_background\")\n",
    "    plt.plot(x, y, marker='o', color='red', label=\"Optimal Tour\")\n",
    "    for i, coord in enumerate(coordinates):\n",
    "        plt.text(coord[0], coord[1], f\"City {i}\", fontsize=8, ha='center', va='center', color='white')\n",
    "    plt.title(\"Optimal Tour\")\n",
    "    plt.xlabel(\"X Coordinate\")\n",
    "    plt.ylabel(\"Y Coordinate\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Usage of the plot_tour function\n",
    "city_coordinates = [(X[i].item(), Y[i].item()) for i in range(len(X))]\n",
    "global_best_position = global_best_position.to('cpu').numpy()  # Convert to CPU and numpy array\n",
    "plot_tour(global_best_position, city_coordinates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimised Code For Both CPU And GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Global observation board\n",
    "observation_board = pd.DataFrame(columns=[\n",
    "    \"Dataset_Size\",\n",
    "    \"Num_Particles\",\n",
    "    \"Num_Iterations\",\n",
    "    \"Num_Cities\",\n",
    "    \"Device\",\n",
    "    \"Best_Score\",\n",
    "    \"Time_Taken(s)\",\n",
    "    \"Global_Best_Position\"\n",
    "])\n",
    "\n",
    "# Logging function\n",
    "def log_observation(dataset_size, num_particles, num_iterations, num_cities, device, best_score, time_taken, global_best_position):\n",
    "    global observation_board\n",
    "    observation_board = pd.concat([\n",
    "        observation_board,\n",
    "        pd.DataFrame([{\n",
    "            \"Dataset_Size\": dataset_size,\n",
    "            \"Num_Particles\": num_particles,\n",
    "            \"Num_Iterations\": num_iterations,\n",
    "            \"Num_Cities\": num_cities,\n",
    "            \"Device\": device,\n",
    "            \"Best_Score\": best_score,\n",
    "            \"Time_Taken(s)\": time_taken,\n",
    "            \"Global_Best_Position\": global_best_position.cpu().numpy().tolist()\n",
    "        }])\n",
    "    ], ignore_index=True)\n",
    "\n",
    "# Euclidean distance computation\n",
    "def euclidean_distance(coords, device):\n",
    "    coords = torch.tensor(coords, device=device)\n",
    "    x_diff = coords[:, 0].unsqueeze(1) - coords[:, 0]\n",
    "    y_diff = coords[:, 1].unsqueeze(1) - coords[:, 1]\n",
    "    return torch.sqrt(x_diff**2 + y_diff**2)\n",
    "\n",
    "# Calculate total distance\n",
    "def calculate_total_distance_batched(tours, distance_matrix):\n",
    "    distances = distance_matrix[tours[:, :-1], tours[:, 1:]].sum(dim=1)\n",
    "    distances += distance_matrix[tours[:, -1], tours[:, 0]]  # Return to start\n",
    "    return distances\n",
    "\n",
    "# Update particles with random swaps\n",
    "def update_particles_batched(particles, distance_matrix):\n",
    "    new_particles = particles.clone()\n",
    "    batch_size, num_cities = particles.shape\n",
    "\n",
    "    indices1 = torch.randint(0, num_cities, (batch_size,), device=distance_matrix.device)\n",
    "    indices2 = torch.randint(0, num_cities, (batch_size,), device=distance_matrix.device)\n",
    "\n",
    "    # Perform swaps\n",
    "    new_particles[range(batch_size), indices1], new_particles[range(batch_size), indices2] = (\n",
    "        new_particles[range(batch_size), indices2],\n",
    "        new_particles[range(batch_size), indices1],\n",
    "    )\n",
    "\n",
    "    # Calculate distances\n",
    "    new_scores = calculate_total_distance_batched(new_particles, distance_matrix)\n",
    "    return new_particles, new_scores\n",
    "\n",
    "# Main PSO function\n",
    "def run_pso(dataset_size, num_particles, num_iterations, device):\n",
    "    # Load data\n",
    "    data_path = f\"/home/nirjhar/Python Codes/Machine Learning/data/archive/{dataset_size}.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "    X, Y = torch.tensor(data['X'].values, device=device), torch.tensor(data['Y'].values, device=device)\n",
    "\n",
    "    # Distance matrix\n",
    "    cities = [(X[i], Y[i]) for i in range(len(X))]\n",
    "    distance_matrix = euclidean_distance(cities, device)\n",
    "\n",
    "    # PSO initialization (To Be Done By Model In Future)\n",
    "    num_cities = distance_matrix.shape[0]\n",
    "    particles = torch.stack([torch.randperm(num_cities, device=device) for _ in range(num_particles)])\n",
    "    personal_best_positions = particles.clone()\n",
    "    personal_best_scores = calculate_total_distance_batched(particles, distance_matrix)\n",
    "    global_best_position = personal_best_positions[torch.argmin(personal_best_scores)]\n",
    "    global_best_score = personal_best_scores.min()\n",
    "    best_scores = []\n",
    "\n",
    "    # Optimization loop\n",
    "    start = time.time()\n",
    "    for _ in tqdm(range(num_iterations), desc=f\"Particles={num_particles}, Iterations={num_iterations}, Device={device}\"):\n",
    "        new_particles, new_scores = update_particles_batched(particles, distance_matrix)\n",
    "\n",
    "        # Update personal bests\n",
    "        better_mask = new_scores < personal_best_scores\n",
    "        personal_best_positions[better_mask] = new_particles[better_mask]\n",
    "        personal_best_scores[better_mask] = new_scores[better_mask]\n",
    "\n",
    "        # Update global best\n",
    "        min_idx = torch.argmin(personal_best_scores)\n",
    "        if personal_best_scores[min_idx] < global_best_score:\n",
    "            global_best_score = personal_best_scores[min_idx]\n",
    "            global_best_position = personal_best_positions[min_idx]\n",
    "\n",
    "        particles = personal_best_positions.clone()\n",
    "        best_scores.append(global_best_score.item())\n",
    "    end = time.time()\n",
    "\n",
    "    # Log results\n",
    "    log_observation(\n",
    "        dataset_size=dataset_size,\n",
    "        num_particles=num_particles,\n",
    "        num_iterations=num_iterations,\n",
    "        num_cities=num_cities,\n",
    "        device=device,\n",
    "        best_score=global_best_score.item(),\n",
    "        time_taken=(end - start),\n",
    "        global_best_position=global_best_position\n",
    "    )\n",
    "\n",
    "    print(f\"Best Score = {global_best_score.item()} units\")\n",
    "    print(f\"Time Taken: {(end - start):.2f} seconds using {device.upper()}\")\n",
    "\n",
    "    # Plot convergence\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(best_scores, label=\"Global Best Distance\", color=\"blue\")\n",
    "    plt.title(f\"Convergence: Particles={num_particles}, Iterations={num_iterations}, Device={device}\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Distance\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    return global_best_position, num_cities, X, Y\n",
    "\n",
    "# Plot the optimal tour\n",
    "def plot_tour(tour, coordinates, num_cities):\n",
    "    if num_cities == 1000:\n",
    "        plt.figure(figsize=(100, 100))\n",
    "    if num_cities == 100:\n",
    "        plt.figure(figsize=(40, 40))\n",
    "    if num_cities == 30:\n",
    "        plt.figure(figsize=(20, 20))\n",
    "    if num_cities == 10:\n",
    "        plt.figure(figsize=(10, 10))\n",
    "    tour_coords = [coordinates[city] for city in tour] + [coordinates[tour[0]]]  # Close the loop\n",
    "    x, y = zip(*tour_coords)\n",
    "    plt.style.use(\"dark_background\")\n",
    "    plt.plot(x, y, marker='o', color='red', label=\"Optimal Tour\")\n",
    "    for i, coord in enumerate(coordinates):\n",
    "        plt.text(coord[0], coord[1], f\"City {i}\", fontsize=8, ha='center', va='center', color='white')\n",
    "    plt.title(f\"Optimal Tour: {num_cities} Cities\")\n",
    "    plt.xlabel(\"X Coordinate\")\n",
    "    plt.ylabel(\"Y Coordinate\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Experiment configurations\n",
    "particle_configs = [10, 50, 100]\n",
    "iteration_configs = [1000, 5000, 10000]\n",
    "dataset_configss = ['tiny', 'small', 'medium', 'large']\n",
    "devices = ['cpu', 'cuda'] if torch.cuda.is_available() else ['cpu']\n",
    "\n",
    "# Run experiments\n",
    "for DATASET_SIZE in dataset_configss:\n",
    "    for device in devices:\n",
    "        for num_particles in particle_configs:\n",
    "            for num_iterations in iteration_configs:\n",
    "                best_position, num_cities, X, Y = run_pso(DATASET_SIZE, num_particles, num_iterations, device)\n",
    "                city_coordinates = [(X[i].item(), Y[i].item()) for i in range(len(X))]\n",
    "                plot_tour(best_position.cpu().numpy(), city_coordinates, num_cities)\n",
    "\n",
    "# Display observation board\n",
    "observation_board\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
